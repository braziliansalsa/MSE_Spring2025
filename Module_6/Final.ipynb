{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOEqfs5SrDwEpEdfEF8ZdwD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeiVKalinin/MSE_Spring2025/blob/main/Module_6/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a final exam for the UTK MSE510 Spring 2025 Course, please choose **2 out of 3** project from the list below, or your own project."
      ],
      "metadata": {
        "id": "gP8-w3fsDeMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 1 is a standard set of problems based on the topics we studied in class (below). Option 2 is applying these methods to your own problem(s) or open-ended problems that are aligned with your current research (I provide below examples that you can use). The general guidelines for the Option 2 are:\n",
        "\n",
        "The project should use in a meaningful fashion\n",
        "1. ODE solving, PDE solving, symbolic regression, DNN, VAE\n",
        "2. Bayesian inference/hypothesis testing, PINNs, causal discovery\n",
        "3. BO based on GP\n",
        "Meaning one or more topic from each group a,b,c. If the problem uses less then 3 elements, you can pick several problems to cover a-c.\n",
        "\n",
        "The examples of the problems can be (you can choose these as final project if you would like):\n",
        "\n",
        "- Multifidelity Ising model exploration. Build the BO loop where 10x10 Ising model is the low fidelity experiment and 30x30 is the high fidelity experiment. Compare it with the standard BO on 30x30 model (e.g. for finding maximum of heat capacity). Explore whether using 10x10 model accelerates the discovery of maximum.\n",
        "- Build network or decision tree for the MNIST. Build Bayesian Optimization workflow in BOTorch or GPax to optimize the system architecture maximizing the precision. Compare the results with optimization for recall.\n",
        "- Build the deep kernel learning workflow for molecular discovery based on open data set. Explore possible molecule representations and run the algorithm to maximize (a) enthalpy, (b) dipole moment."
      ],
      "metadata": {
        "id": "lNRhmsJJZbB5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Choose 2 out of 3.** When submitting the final, please make sure that each point in the bulleted list becomes the section in submitted Colab and Colab can run from the beginnign to the end."
      ],
      "metadata": {
        "id": "iUb-laHVZ0GM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VAE as generative model"
      ],
      "metadata": {
        "id": "x-jkhFV-FCqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Select dataset (standard or your own) that comprizes some high dimensional data (e.g. images or molecular represnetations) and labels (e.g. attributes such as \"beard/no beard\", \"glasses/no glasses\" for images, or molecular properties). If the data set is too large for the Colab, feel free to downscale image resolution, select subset of data, etc.\n",
        "- Build or adapt the variational autoencoder that can work with the data\n",
        "- Construct the latent representation and latent distribution of the data (for 2D latent space)\n",
        "- Plot the reconstruction error and KL divergence erros as a function of the dimensionality of the latent space (say from 1 to 10)\n",
        "- Explore the distribution of ground truth labels in 2D latent space\n",
        "- Implement the generative model - e.g. build the (linear) relationship between the labels and latent variables, and check if you can change the attibute of image (e.g. encode the image into the latent space, shift it across the direction responsible for certain attribute, and decode from this point)\n"
      ],
      "metadata": {
        "id": "YaRwZYUQLVWw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFGi7FeqH7lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D Ising Exploration"
      ],
      "metadata": {
        "id": "WIgcibIPOBer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create Ising Function that will return thermodynamic parameter as a function of two exchange integrals\n",
        "- Explore 2D Ising in the Jc, Js parameter space using Bayesian Optimization.\n",
        "- Realize pure exploratory algorithms minimizing the uncertainty\n",
        "- Realize the greedy algoritm that will attempt to maximize the chosen thermodynamic parameter\n",
        "- Compare the difference\n",
        "- Ideally the output will be the video illustarting the exploration process and evolution of prediction, uncertainty, and acquisition function."
      ],
      "metadata": {
        "id": "EnbqKew0Lt8E"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o2cubGt2OFFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Symbolic Regression as an input to Bayesian Optimization"
      ],
      "metadata": {
        "id": "uNptClvkOFij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Select a own data set (either standard optimization function like Auckley of Forrestal, or just some interesting function like A sin (b x) + c x, Bessel function, etc.)\n",
        "- Generate data by sampling this function with noise, sigma, over certain interval (e.g. [0, 5])\n",
        "- Do symbolic regression over the interval\n",
        "- Choose 3 possible functions generated by PySR\n",
        "- Create the probabilistic models based on these functions (meaning convert them to the probabilistic models and add the priors on parameters).\n",
        "- Do Bayesian Inference for all three functions\n",
        "- Calculate WAIC\n",
        "- Plot the predicitive mean and uncertainty for all three models over larger interval (e.g. [-5, 10]); compare to the ground truth\n",
        "- Plot the integrated predictive uncertainty and the MSE between prediction and ground truth as a function of noise, sigma, during sampling.  "
      ],
      "metadata": {
        "id": "KmFu7uyKOMGk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AQv54kRBKui7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}